---
title: "Application Exam 2"
author: "myname"
date: "`r lubridate::today()`"
format: 
  html: 
    embed-resources: true
    toc: true 
    toc_depth: 4
editor_options: 
  chunk_output_type: console
---

## Setup

### Set Conflict Policy

```{r}
options(conflicts.policy = "depends.ok")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_ml.R?raw=true")
tidymodels_conflictRules()
```

### Load Required Packages

```{r}
library(tidyverse) 
library(tidymodels)
library(foreach, exclude = c("accumulate", "when"))
library(doParallel)
library(ranger)
library(xfun, include.only = "cache_rds")
library(cowplot, include.only = c("plot_grid", "theme_half_open"))
library(corrplot, include.only = "corrplot.mixed")
library(naniar)
```

### Add Additional Packages

```{r}
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_eda.R?raw=true")
devtools::source_url("https://github.com/jjcurtin/lab_support/blob/main/fun_plots.R?raw=true")
```

## Set Global Options
```{r}
options(tibble.width = Inf, tibble.print_max = Inf)
theme_set(theme_bw()) 
path_data <- "exam/data"
```

# Part One: Prediction

## CLEANING EDA (FULL DATASET)

First we read in the data_full:

```{r}
data_full <- read_csv(here::here(path_data, "airline_passenger_satisfaction.csv"), 
                 col_types = cols()
                 ) |> 
  glimpse()
```

I notice gender is capitalized, let's correct it to snake-case before moving on:

```{r}
data_full <- data_full |> 
  janitor::clean_names("snake")

data_full |> glimpse()
```

Confirm that variables have been read in as the expected class:

```{r}
data_full |> 
  skim_some() 
```

It seems that many factor variables are mis-classified as numeric or characters, let's fix that:

```{r}
data_full <- data_full |> 
  mutate(
    across(where(is.character), factor),
    
    across(c(inflight_wifi_service, 
             departure_arrival_time_convenient, 
             ease_of_online_booking, 
             gate_location, 
             food_and_drink,
             online_boarding, 
             seat_comfort, 
             inflight_entertainment,
             onboard_service, 
             leg_room_service, 
             baggage_handling,
             checkin_service, 
             inflight_service, 
             cleanliness), 
           factor)
  )
```

```{r}
data_full |> glimpse()
```


Now that the variables are properly classified, let's look at missingness:

```{r}
data_full |> 
  skim_some() |> 
  select(skim_variable, n_missing, complete_rate)
```

It seems we have missing points for `gender`, `online_boarding`, `onboard_service`, `departure_delay_in_minutes`, and `arrival_delay_in_minutes`.

Let's look at the levels, to see what might be going on:

```{r}
data_full$gender |> levels()
data_full$customer_class |> levels()
data_full$online_boarding |> levels()

data_full |> filter(is.na(gender)) |>
  print_kbl()

data_full |> filter(is.na(customer_class)) |>
  print_kbl()

data_full |> filter(is.na(online_boarding)) |>
  print_kbl()
```

There doesn't seem to be any glaring data_full quality issues or incorrectly coded information. I will need to look into these values more after I split my data_full.

Let's now look into the distributions of our numeric variables:

```{r}
data_full |>
  skim_some() |> 
  filter(skim_type == "numeric") |>
  select(skim_variable, numeric.p0, numeric.p100)
```

Everything seems reasonable.

Let's clean our response labels for our categorical variables. I dislike how long the the "not_satisfied" category is, and there isn't any variation in the data anyways.

```{r}
data_full |> 
  select(where(is.factor)) |>
  walk(\(column) print(levels(column)))
```

```{r}
data_full <- data_full |>
  mutate(across(where(is.factor), tidy_responses))

data_full <- data_full |> 
  mutate(satisfaction = fct_recode(satisfaction,
                                   "not_satisfied" = "neutral_or_dissatisfied"))
data_full |> 
  select(where(is.factor)) |>
  walk(\(column) print(levels(column)))

```

CLEANING EDA: SPLIT DATA INTO TEST SETS

Now that our data is nice and clean, let's make the splits

```{r}
set.seed(115)
splits <- initial_split(data_full, 
                           prop = 0.8,  # 80% training, 20% testing
                           strata = satisfaction)  # Stratify on outcome
```

```{r}
splits |> 
  analysis() |> 
  glimpse() |> 
  write_csv(here::here(path_data, "airline_train.csv"))
```

```{r}
splits |> 
  assessment() |> 
  glimpse() |> 
  write_csv(here::here(path_data, "airline_test.csv"))
```

## EDA: MODELING

Let's read in our training set:

```{r}
data_train <- read_csv(here::here(path_data, "airline_train.csv"), 
                       show_col_types = cols()
                       ) |> 
  glimpse()
```

Let's reclassify our variables appropriately:

```{r}
data_train <- data_train |> 
  mutate(
    across(where(is.character), factor),
    
    across(c(inflight_wifi_service, 
             departure_arrival_time_convenient, 
             ease_of_online_booking, 
             gate_location, 
             food_and_drink,
             online_boarding, 
             seat_comfort, 
             inflight_entertainment,
             onboard_service, 
             leg_room_service, 
             baggage_handling,
             checkin_service, 
             inflight_service, 
             cleanliness), 
           factor)
  )
```

Firstly, I want to see if we are dealing with a significant class imbalance.

```{r}
data_train |>  
  count(satisfaction) |>  
  mutate(prop = n/sum(n))
```

Our proportion is 1/3 in the negative class, and 2/3 in the positive class. This is mild imbalance, and pushes me to consider algorithms and metric that handle imbalance better. Right now I am leaning towards a tree-based algorithm and F1.

Let's take a larger look at the data:

```{r}
data_train |> skim_all()
```

Let's figure out our missing data:

```{r}
gg_miss_upset(data_train)
```

- `gender` has the largest number of missing values (81)
- `online_boarding` has 28 missing values
- `onboard_service` has 13 missing values
- There are some observations with multiple missing values (e.g., 8 cases missing both `gender` and `online_boarding`)

Let's look into it more:

Ignoring `gender` and `online_boarding`, my hypothesis is that participants did not respond to the question as a stand-in for there being any accurate level for "no variable".

Let's check `online_boarding`'s relationships with other variables

```{r}
# Check relationship between online_boarding missingness and customer_type
data_train %>%
  mutate(online_boarding_missing = is.na(online_boarding)) %>%
  group_by(customer_type) %>%
  summarize(
    n = n(),
    pct_missing = mean(online_boarding_missing) * 100,
    satisfaction_rate = mean(satisfaction == "satisfied") * 100
  )

# Check relationship with type_of_travel (business vs personal)
data_train %>%
  mutate(online_boarding_missing = is.na(online_boarding)) %>%
  group_by(type_of_travel) %>%
  summarize(
    n = n(),
    pct_missing = mean(online_boarding_missing) * 100
  )

# Check if online_boarding missingness relates to ease_of_online_booking
data_train %>%
  mutate(online_boarding_missing = is.na(online_boarding)) %>%
  group_by(ease_of_online_booking) %>%
  summarize(
    n = n(),
    pct_missing = mean(online_boarding_missing) * 100
  )
```

